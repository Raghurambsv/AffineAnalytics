{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "[1. Establishing Goals](#1.-Establishing-Goals)\n",
    "\n",
    "[2. Introduction to Dataset](#2.-Introduction-to-Dataset)\n",
    "\n",
    "[3. Exploratory Data Analysis](#3.-Exploratory-Data-Analysis)\n",
    "\n",
    "[4. Limit Data to Scope](#4.-Limit-Data-to-Scope)\n",
    "\n",
    "[5. Supervised Feature Generation](#5.-Supervised-Feature-Generation)\n",
    "    \n",
    "- [5.1 Common Bag of Words](#5.1-Common-Bag-of-Words)\n",
    "- [5.2 Turn Common Words into Features](#5.2-Turn-Common-Words-into-Features)\n",
    "- [5.3 Clustering on BOW](#5.3.-Clustering-on-BOW)\n",
    "- [5.4 Classification on BOW](#5.4.-Classification-on-BOW)\n",
    "\n",
    "[6. Unsupervised Feature Generation](#6.-Unsupervised-Feature-Generation)\n",
    "\n",
    "- [6.1 Latent Semantic Analysis](#6.1.-Latent-Semantic-Analysis)\n",
    "- [6.2 Clustering on LSA (BOW Content)](#6.2.-Clustering-on-LSA-(BOW-Content))\n",
    "- [6.3 Classification on LSA (BOW Content)](#6.3.-Classification-on-LSA-(BOW-Content))\n",
    "- [6.4 Clustering on LSA (All Content)](#6.4.-Clustering-on-LSA-(All-Content))\n",
    "- [6.5 Classification on LSA (All Content)](#6.5.-Classification-on-LSA-(All-Content))\n",
    "\n",
    "[7. Choosing Model](#7.-Choosing-Model)\n",
    "\n",
    "- [7.1 Comparing Scores](#7.1.-Comparing-Scores)\n",
    "- [7.2 Sorting by Test Accuracy](#7.2.-Sorting-by-Test_Accuracy)\n",
    "- [7.3 Winner](#7.3.-Winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Establishing Goals\n",
    "\n",
    "In this project I'll attempt to build models to correctly predict the author of a given article. The scope will be limited to 10 authors. The techniques I'll compare will include `Bag-of-Words` VS `Latent Semantic Analysis` for feature-generation, and `Clustering` VS `Supervised Learning` for classification. I'll also experiment with different sample sizes, as feature-generation can be very sensitive to high dimensionality.\n",
    "\n",
    "# 2. Introduction to DataSet\n",
    "\n",
    "**From:** https://www.kaggle.com/snapcrack/all-the-news\n",
    "\n",
    "This dataset contains news articles scraped from various publications, labeled by publication and author name, as well as date and title.\n",
    "\n",
    "The original source on `kaggle.com` contains three `.csv` files. Accross the three, there are over 140,000 articles from a total of 15 publications. \n",
    "\n",
    "The dataset used here is only the first of those three files, which contains about a third of all the data at roughly `280MB`. This is more than enough data for the goals of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis\n",
    "\n",
    "Let's get a quick overview of the data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General-purpose Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "\n",
    "# Tools for processing data\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, classification_report, confusion_matrix, make_scorer, adjusted_rand_score, silhouette_score, homogeneity_score, normalized_mutual_info_score\n",
    "# Classifiers, supervised and unsupervised\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into a DataFrame\n",
    "data = pd.read_csv('articles2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53293</td>\n",
       "      <td>73471</td>\n",
       "      <td>Patriots Day Is Best When It Digs Past the Her...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>David Sims</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patriots Day, Peter Berg’s new thriller that r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53294</td>\n",
       "      <td>73472</td>\n",
       "      <td>A Break in the Search for the Origin of Comple...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Ed Yong</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Norse mythology, humans and our world were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53295</td>\n",
       "      <td>73474</td>\n",
       "      <td>Obama’s Ingenious Mention of Atticus Finch</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Spencer Kornhaber</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>“If our democracy is to work in this increasin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                              title  \\\n",
       "0       53293  73471  Patriots Day Is Best When It Digs Past the Her...   \n",
       "1       53294  73472  A Break in the Search for the Origin of Comple...   \n",
       "2       53295  73474         Obama’s Ingenious Mention of Atticus Finch   \n",
       "\n",
       "  publication             author        date    year  month  url  \\\n",
       "0    Atlantic         David Sims  2017-01-11  2017.0    1.0  NaN   \n",
       "1    Atlantic            Ed Yong  2017-01-11  2017.0    1.0  NaN   \n",
       "2    Atlantic  Spencer Kornhaber  2017-01-11  2017.0    1.0  NaN   \n",
       "\n",
       "                                             content  \n",
       "0  Patriots Day, Peter Berg’s new thriller that r...  \n",
       "1  In Norse mythology, humans and our world were ...  \n",
       "2  “If our democracy is to work in this increasin...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "data.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for Missing Data**\n",
    "\n",
    "- The content feature is complete. That's the most important thing. Some author names are missing. We'll make sure to choose 10 properly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49999 entries, 0 to 49998\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   49999 non-null  int64  \n",
      " 1   id           49999 non-null  int64  \n",
      " 2   title        49998 non-null  object \n",
      " 3   publication  49999 non-null  object \n",
      " 4   author       41401 non-null  object \n",
      " 5   date         47373 non-null  object \n",
      " 6   year         47373 non-null  float64\n",
      " 7   month        47373 non-null  float64\n",
      " 8   url          42988 non-null  object \n",
      " 9   content      49999 non-null  object \n",
      "dtypes: float64(2), int64(2), object(6)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Length of Articles**\n",
    "- In terms of number of characters, the average article has less than 4,000 letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Summary of Article Lengths\n",
      "count     49999.000000\n",
      "mean       4216.535491\n",
      "std        5103.596233\n",
      "min           2.000000\n",
      "25%        1725.000000\n",
      "50%        3199.000000\n",
      "75%        5074.000000\n",
      "max      164658.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = pd.Series([len(x) for x in data.content])\n",
    "print('Statistical Summary of Article Lengths')\n",
    "print(lengths.describe())\n",
    "\n",
    "sns.distplot(lengths,kde=False)\n",
    "plt.title('Distribution of Article Lengths (All)')\n",
    "plt.show()\n",
    "sns.distplot(lengths[lengths<10000],kde=False)\n",
    "plt.title('Distribution of Articles Lengths < 10,000 Characters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Limit Data to Scope\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "Here I'll pick the 10 authors whose names I'll predict based on their content. This selection will remain the same for all the methods I'll compare.\n",
    "\n",
    "Since we only need 10 authors, I'll get the first 10 authors whose article-count is greater than X. 100 articles per author is a good number because more would take terribly long when fit to classifiers after `TF-IDF`. At the same time, `Bag-of-Words` is the slowest. However, for that I'll limit to 50 of these articles per author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lois Weiss             110\n",
      "Todd Starnes           110\n",
      "Emily Saul             109\n",
      "Chris Geidner          109\n",
      "Bourree Lam            106\n",
      "James Fallows          106\n",
      "Jaclyn Hendricks       105\n",
      "Alexandra DeSanctis    105\n",
      "Jamie Schram           104\n",
      "Carleton English       103\n",
      "Name: author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# First ten authors with more than X articles\n",
    "print(data.author.value_counts()[data.author.value_counts()>100][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are the top real estate deals of 2016</td>\n",
       "      <td>Excitement has not been lacking in an industry...</td>\n",
       "      <td>Lois Weiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Celebs losing beloved Plaza Hotel spa</td>\n",
       "      <td>The Plaza Hotel is losing its   spa. The Plaza...</td>\n",
       "      <td>Lois Weiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brookfield Place is becoming a mecca for men’s...</td>\n",
       "      <td>Downtown’s Brookfield Place, also owned by Bro...</td>\n",
       "      <td>Lois Weiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two new retailers setting up shop in Williamsburg</td>\n",
       "      <td>Two retailers are opening stores on Williamsbu...</td>\n",
       "      <td>Lois Weiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245 Park Ave. poised to sell for over $2B</td>\n",
       "      <td>The first trophy office building of the year h...</td>\n",
       "      <td>Lois Weiss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         Here are the top real estate deals of 2016   \n",
       "1              Celebs losing beloved Plaza Hotel spa   \n",
       "2  Brookfield Place is becoming a mecca for men’s...   \n",
       "3  Two new retailers setting up shop in Williamsburg   \n",
       "4          245 Park Ave. poised to sell for over $2B   \n",
       "\n",
       "                                             content      author  \n",
       "0  Excitement has not been lacking in an industry...  Lois Weiss  \n",
       "1  The Plaza Hotel is losing its   spa. The Plaza...  Lois Weiss  \n",
       "2  Downtown’s Brookfield Place, also owned by Bro...  Lois Weiss  \n",
       "3  Two retailers are opening stores on Williamsbu...  Lois Weiss  \n",
       "4  The first trophy office building of the year h...  Lois Weiss  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a DataFrame with articles by our chosen authors\n",
    "# Include author names and article titles.\n",
    "\n",
    "# Make a list of the 10 chosen author names\n",
    "names = data.author.value_counts()[data.author.value_counts()>100][-10:].index.tolist()\n",
    "\n",
    "# DataFrame for articles of all chosen authors\n",
    "authors_data = pd.DataFrame()\n",
    "for name in names:\n",
    "    # Select each author's data\n",
    "    articles = data[data.author==name][:100][['title','content','author']]\n",
    "    # Append it to the DataFrame\n",
    "    authors_data = authors_data.append(articles)\n",
    "\n",
    "authors_data = authors_data.reset_index().drop('index',1)\n",
    "    \n",
    "authors_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 1000\n",
      "Unique articles: 1000\n",
      "Unique authors: 10\n",
      "\n",
      "Articles by author:\n",
      "\n",
      "Jaclyn Hendricks       100\n",
      "Alexandra DeSanctis    100\n",
      "Bourree Lam            100\n",
      "James Fallows          100\n",
      "Jamie Schram           100\n",
      "Todd Starnes           100\n",
      "Lois Weiss             100\n",
      "Chris Geidner          100\n",
      "Emily Saul             100\n",
      "Carleton English       100\n",
      "Name: author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look for duplicates\n",
    "print('Number of articles:',authors_data.shape[0])\n",
    "print('Unique articles:',len(np.unique(authors_data.index)))\n",
    "\n",
    "# Number of authors\n",
    "print('Unique authors:',len(np.unique(authors_data.author)))\n",
    "print('')\n",
    "print('Articles by author:\\n')\n",
    "\n",
    "# Articles counts by author\n",
    "print(authors_data.author.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at the Size of Articles Chosen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Summary of Article Lengths\n",
      "count     1000.000000\n",
      "mean      6563.094000\n",
      "std      12433.722696\n",
      "min        107.000000\n",
      "25%       1576.000000\n",
      "50%       2659.000000\n",
      "75%       4437.500000\n",
      "max      87479.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = pd.Series([len(x) for x in authors_data.content])\n",
    "print('Statistical Summary of Article Lengths')\n",
    "print(lengths.describe())\n",
    "\n",
    "sns.distplot(lengths,kde=False)\n",
    "plt.title('Distribution of Article Lengths (All)')\n",
    "plt.show()\n",
    "sns.distplot(lengths[lengths<10000],kde=False)\n",
    "plt.title('Distribution of Articles Lengths < 10,000 Characters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Supervised Feature Generation\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "Bag of words is a list of the most common words of a given source of text. To identify each author, I'll create a bag of words containing the most-common words of all authors combined. This set later becomes the basis for feature engineering.\n",
    "\n",
    "## 5.1 Common Bag of Words\n",
    "- Here I'll extract the most-common 1000 words from each author's corpus, store them in a list, and then eliminate duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E088] Text of length 3745117 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-68092bfecbfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0marticle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Let Spacy parse the author's body of text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Store the doc in the dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             raise ValueError(\n\u001b[1;32m--> 429\u001b[1;33m                 \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE088\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m             )\n\u001b[0;32m    431\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E088] Text of length 3745117 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`."
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Load spacy NLP object\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "# A list to store common words by all authors\n",
    "common_words = []\n",
    "\n",
    "# A dictionary to store the spacy_doc object of each author\n",
    "authors_docs = {}\n",
    "\n",
    "for name in names:\n",
    "    # Corpus is all the text written by that author\n",
    "    corpus = \"\"\n",
    "    # Grab all rows of current author, along the 'content' column\n",
    "    author_content = authors_data.loc[authors_data.author==name,'content']\n",
    "    \n",
    "    # Merge all articles in to the author's corpus\n",
    "    for article in author_content:\n",
    "        corpus = corpus + article\n",
    "    # Let Spacy parse the author's body of text\n",
    "    doc = nlp(corpus)\n",
    "    \n",
    "    # Store the doc in the dictionary\n",
    "    authors_docs[name] = doc\n",
    "        \n",
    "    # Filter out punctuation and stop words.\n",
    "    lemmas = [token.lemma_ for token in doc\n",
    "                if not token.is_punct and not token.is_stop]\n",
    "        \n",
    "    # Return the most common words of that author's corpus.\n",
    "    bow = [item[0] for item in Counter(lemmas).most_common(1000)]\n",
    "    \n",
    "    # Add them to the list of words by all authors.\n",
    "    for word in bow:\n",
    "        common_words.append(word)\n",
    "\n",
    "# Eliminate duplicates\n",
    "common_words = set(common_words)\n",
    "    \n",
    "print('Total number of common words:',len(common_words))\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From a theorical total of 10,000 common-words, (1,000 from 10 authors) 3,405 were unique. So roughly a third of all words used by each author is actually part of their unique style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see our 10 authors in the dictionary\n",
    "lengths = []\n",
    "for k,v in authors_docs.items():\n",
    "    print(k,'corpus contains',len(v),' words.')\n",
    "    lengths.append(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=lengths,y=names,orient='h')\n",
    "plt.title('Word Count per Author in Chosen Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Turn Common Words into Features\n",
    "\n",
    "**Approach**\n",
    "\n",
    "Due to the curse of dimensionality, doing this step with all our 1,000 articles would take prohibitively long. (10 authors * 100 articles/ea = 1,000 articles)  At 30 seconds per article, my personal machine would need 8.5 hours of processing. Therefore I'll limit this part to 50 articles per author. This should still convey enough information for a decent predictive model.\n",
    "\n",
    "**About 'Common Bag of Words'**\n",
    "\n",
    "This technique consists of creating a feature out of each common word and then counting the number of times each common word appears in each article. Each cell will represent the number of times the lemma of the given column appears in the article of the current row. We have over 3,000 common words, and will be using 500 articles total. (50 per author) Plus each article may have a varying number of words in it. That's a lot of text to compare and count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for lower case words\n",
    "common_words = pd.Series(pd.DataFrame(columns=common_words).columns)\n",
    "print('Count of all common_words:',len(common_words))\n",
    "print('Count of lowercase common_words:',np.sum([word.islower() for word in common_words]))\n",
    "\n",
    "# Turn all common_words into lower case\n",
    "common_words = [word.lower() for word in common_words]\n",
    "print('Count of lowercase common_words (After Conversion):',np.sum([word.islower() for word in common_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that after converting to lowercase the total number of lowercase words still isn't the same as the total. This means there are around 100 non alphabetic words inside our bag. This is probably made up of numbers and words with punctuations within.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must remove these in to avoid conflicts with existing features.\n",
    "if 'author' in common_words:\n",
    "    common_words.remove('author')\n",
    "if 'title' in common_words:\n",
    "    common_words.remove('title')\n",
    "if 'content' in common_words:\n",
    "    common_words.remove('content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times a common_word appears in each article\n",
    "# (about 3Hrs processing)\n",
    "\n",
    "bow_counts = pd.DataFrame()\n",
    "for name in names:\n",
    "    # Select X articles of that author\n",
    "    articles = authors_data.loc[authors_data.author==name,:][:50]\n",
    "    bow_counts = bow_counts.append(articles)\n",
    "bow_counts = bow_counts.reset_index().drop('index',1)\n",
    "\n",
    "# Use common_words as the columns of a temporary DataFrame\n",
    "df = pd.DataFrame(columns=common_words)\n",
    "\n",
    "# Join BOW features with the author's content\n",
    "bow_counts = bow_counts.join(df)\n",
    "\n",
    "# Initialize rows with zeroes\n",
    "bow_counts.loc[:,common_words] = 0\n",
    "\n",
    "# Fill the DataFrame with counts of each feature in each article\n",
    "t0 = time()\n",
    "for i, article in enumerate(bow_counts.content):\n",
    "    doc = nlp(article)\n",
    "    for token in doc:\n",
    "        if token.lemma_.lower() in common_words:\n",
    "            bow_counts.loc[i,token.lemma_.lower()] += 1\n",
    "    # Print a message every X articles\n",
    "    if i % 50 == 0:\n",
    "        if time()-t0 < 3600: # if less than an hour in seconds\n",
    "            print(\"Article \",i,\" done after \",(time()-t0)/60,' minutes.')\n",
    "        else:\n",
    "            print(\"Article \",i,\" done after \",(time()-t0)/60/60,' hours.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is the data that we can use to train clusters and classifiers. Each entry is an article, each column is a common word, and each cell is a count of the current common word in the current article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_counts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:**\n",
    "\n",
    "- Store contents of `bow_counts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the long-awaited data into a pickle file for easy recovery\n",
    "#bow_counts.to_pickle('bow_counts')\n",
    "\n",
    "# Read it back in with the following\n",
    "#bow_counts = pd.read_pickle('bow_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make sure we have 50 articles per author\n",
    "bow_counts.author.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Clustering on BOW\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "- Before classifying, I'll start with clustering. Here I'll create clusters out of the BOW data and see if those clusters resemble the actual author's content. Clusters have no labels, but similar content tends to fall into the same clusters. Therefore in an ideal clustering solution, each author's articles would all fall into a single cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish outcome and predictors\n",
    "y = bow_counts['author']\n",
    "X = bow_counts.drop(['content','author','title'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.24,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure classes are balanced after train-test-split\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame to Store our Results**\n",
    "\n",
    "This `DataFrame` will hold results from all algorithms implemented ahead. For clustering algorithms, the train/test and cross_val columns will be left blank because clustering requires no train/test split. On the other hand, classifiers will inded store their own `ARI, Homogeneity, Silhouette, and Mutual_Info` scores. `Features` will represent the method for feature-engineering, whether BOW or LSA. And the `n_train` column will represent the number of samples in the train size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store our results in a DataFrame\n",
    "metrics = ['Algorithm','n_train','Features','ARI','Homogeneity',\n",
    "           'Silhouette','Mutual_Info','Cross_Val','Train_Accuracy',\n",
    "           'Test_Accuracy']\n",
    "performance = pd.DataFrame(columns=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach to Clustering**\n",
    "\n",
    "In cluster analysis, there usually is no training or test data split. Because you do cluster analysis when you do not have labels, so you cannot \"train\".Training is a concept from machine learning, and train-test splitting is used to avoid overfitting. But if you are not learning labels, you cannot overfit. Properly used cluster analysis is a knowledge discovery method. You want to discover some new structure in your data, not rediscover something that is already labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. Unsupervised Parameter Search Function\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "- This function will find the parameters that produce the highest `Normalized Mutual Infomation` score from our clusters. This score is a good baseline from which to compare clustering VS classification because it correlates with good clutering as well as higher accuracy scores.\n",
    "- It'll print the relevant statistics as well as a contingency matrix of the result and lastly store our results in an external DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to quickly evaluate clustering solutions\n",
    "def evaluate_clust(clust,params,features,i):\n",
    "    t0 = time()\n",
    "    print('\\n','-'*40,'\\n',clust.__class__.__name__,'\\n','-'*40)\n",
    "    \n",
    "    # Find best parameters based on scoring of choice\n",
    "    score = make_scorer(normalized_mutual_info_score)\n",
    "    search = GridSearchCV(clust,params,scoring=score,cv=3).fit(X,y)\n",
    "    print(\"Best parameters:\",search.best_params_)\n",
    "    y_pred = search.best_estimator_.fit_predict(X)\n",
    "\n",
    "    ari = adjusted_rand_score(y, y_pred)\n",
    "    performance.loc[i,'ARI'] = ari \n",
    "    print(\"Adjusted Rand-Index: %.3f\" % ari)\n",
    "    \n",
    "    hom = homogeneity_score(y,y_pred)\n",
    "    performance.loc[i,'Homogeneity'] = hom\n",
    "    print(\"Homogeneity Score: %.3f\" % hom)\n",
    "    \n",
    "    sil = silhouette_score(X,y_pred)\n",
    "    performance.loc[i,'Silhouette'] = sil\n",
    "    print(\"Silhouette Score: %.3f\" % sil)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(y,y_pred)\n",
    "    performance.loc[i,'Mutual_Info'] = nmi\n",
    "    print(\"Normed Mutual-Info Score: %.3f\" % nmi)\n",
    "    \n",
    "    performance.loc[i,'n_train'] = len(X)\n",
    "    performance.loc[i,'Features'] = features\n",
    "    performance.loc[i,'Algorithm'] = clust.__class__.__name__\n",
    "    \n",
    "    # Print contingency matrix\n",
    "    crosstab = pd.crosstab(y, y_pred)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.heatmap(crosstab, annot=True,fmt='d', cmap=plt.cm.copper)\n",
    "    plt.show()\n",
    "    print(time()-t0,\"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. KMeans CBOW\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust=KMeans()\n",
    "params={\n",
    "    'n_clusters': np.arange(10,30,5),\n",
    "    'init': ['k-means++','random'],\n",
    "    'n_init':[10,20],\n",
    "    'precompute_distances':[True,False]\n",
    "}\n",
    "evaluate_clust(clust,params,features='BOW',i=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3. Mean Shift CBOW\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Declare and fit the model\n",
    "clust = MeanShift()\n",
    "\n",
    "params={}\n",
    "evaluate_clust(clust,params,features='BOW',i=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above is a really bad solution. 30 clusters were created but most of our articles were assigned to the first cluster.\n",
    "\n",
    "### 5.3.4. Affinity Propagation CBOW\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare and fit the model.\n",
    "clust = AffinityPropagation()\n",
    "\n",
    "params = {\n",
    "    'damping':[.5,.7,.9],\n",
    "    'max_iter':[200,500]\n",
    "}\n",
    "evaluate_clust(clust,params,features='BOW',i=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above solution generated too many clusters to be properly visualized. However, the `Mutual_Info` score is quite decent because datapoints may be falling onto pockets that resemble the true labels.\n",
    "\n",
    "### 5.3.5. Spectral Clustering CBOW\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "- SpectralClustering can't be used with GridSearchCV because it lacks a .fit method. Therefore I won't use the function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust= SpectralClustering()\n",
    "\n",
    "params = {\n",
    "    'n_clusters':np.arange(10,26,5),\n",
    "    #'eigen_solver':['arpack','lobpcg',None],\n",
    "    'n_init':[15,25],\n",
    "    'assign_labels':['kmeans','discretize']\n",
    "}\n",
    "\n",
    "features='BOW'\n",
    "\n",
    "i=3\n",
    "\n",
    "t0=time()\n",
    "\n",
    "y_pred = clust.fit_predict(X)\n",
    "\n",
    "ari = adjusted_rand_score(y, y_pred)\n",
    "performance.loc[i,'ARI'] = ari \n",
    "print(\"Adjusted Rand-Index: %.3f\" % ari)\n",
    "\n",
    "hom = homogeneity_score(y,y_pred)\n",
    "performance.loc[i,'Homogeneity'] = hom\n",
    "print(\"Homogeneity Score: %.3f\" % hom)\n",
    "\n",
    "sil = silhouette_score(X,y_pred)\n",
    "performance.loc[i,'Silhouette'] = sil\n",
    "print(\"Silhouette Score: %.3f\" % sil)\n",
    "\n",
    "nmi = normalized_mutual_info_score(y,y_pred)\n",
    "performance.loc[i,'Mutual_Info'] = nmi\n",
    "print(\"Normed Mutual-Info Score: %.3f\" % nmi)\n",
    "\n",
    "performance.loc[i,'n_train'] = len(X)\n",
    "performance.loc[i,'Features'] = features\n",
    "performance.loc[i,'Algorithm'] = clust.__class__.__name__\n",
    "\n",
    "# Print contingency matrix\n",
    "crosstab = pd.crosstab(y, y_pred)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(crosstab, annot=True,fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()\n",
    "print(time()-t0,\"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.iloc[:,:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on `Mutual_Info`, our highest score came from `AffinityPropagation`. However, the large number of clusters dividing our articles makes the solution a bit impractical.\n",
    "- Fortunately we can perform supervised classification on this dataset because we actually do know who wrote these articles.\n",
    "\n",
    "## 5.4. Classification on BOW\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1. Supervised Parameter Search Function\n",
    "\n",
    "- The following function will print cross-validation, train and test accuracy scores in addition to the clustering scores we've been utilizing previously.\n",
    "- The `GridSearchCV` will also find the parameters that produce the highest `Normalized Mutual Information` score.\n",
    "- There is a very clear correlation between the `Mutual_Info` score and the `Test_Accuracy` from our classifiers.\n",
    "- Notice that here the `n_train` will be smaller than in the previous section because here we are actually doing a train/test split, whereas in the previous section we used `fit_predict(X)` on the clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_optimization(clf,params,features,i):\n",
    "    t0 = time()\n",
    "    # Heading\n",
    "    print('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n",
    "    \n",
    "    # Find best parameters based on scoring of choice\n",
    "    score = make_scorer(normalized_mutual_info_score)\n",
    "    search = GridSearchCV(clf,params,\n",
    "                          scoring=score,cv=3).fit(X,y)\n",
    "    # Extract best estimator\n",
    "    best = search.best_estimator_\n",
    "    print(\"Best parameters:\",search.best_params_)\n",
    "\n",
    "    # Cross-validate on all the data\n",
    "    cv = cross_val_score(X=X,y=y,estimator=best,cv=5)\n",
    "    print(\"\\nCross-val scores(All Data):\",cv)\n",
    "    print(\"Mean cv score:\",cv.mean())\n",
    "    performance.loc[i,'Cross_Val'] = cv.mean() \n",
    "    \n",
    "    # Get train accuracy\n",
    "    best = best.fit(X_train,y_train)\n",
    "    train = best.score(X=X_train,y=y_train)\n",
    "    performance.loc[i,'Train_Accuracy'] = train \n",
    "    print(\"\\nTrain Accuracy Score:\",train)\n",
    "\n",
    "    # Get test accuracy\n",
    "    test = best.score(X=X_test,y=y_test)\n",
    "    performance.loc[i,'Test_Accuracy'] = test \n",
    "    print(\"\\nTest Accuracy Score:\",test)\n",
    "    \n",
    "    y_pred = best.predict(X_test)\n",
    "    \n",
    "    ari = adjusted_rand_score(y_test, y_pred)\n",
    "    performance.loc[i,'ARI'] = ari \n",
    "    print(\"\\nAdjusted Rand-Index: %.3f\" % ari)\n",
    "    \n",
    "    hom = homogeneity_score(y_test,y_pred)\n",
    "    performance.loc[i,'Homogeneity'] = hom\n",
    "    print(\"Homogeneity Score: %.3f\" % hom)\n",
    "    \n",
    "    sil = silhouette_score(X_test,y_pred)\n",
    "    performance.loc[i,'Silhouette'] = sil\n",
    "    print(\"Silhouette Score: %.3f\" % sil)\n",
    "    \n",
    "    nmi = normalized_mutual_info_score(y_test,y_pred)\n",
    "    performance.loc[i,'Mutual_Info'] = nmi\n",
    "    print(\"Normed Mutual-Info Score: %.3f\" % nmi)\n",
    "\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "\n",
    "    conf_matrix = pd.crosstab(y_test,y_pred)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "    plt.show()\n",
    "    \n",
    "    performance.loc[i,'n_train'] = len(X_train)\n",
    "    performance.loc[i,'Features'] = features\n",
    "    performance.loc[i,'Algorithm'] = clf.__class__.__name__\n",
    "    print(time()-t0,'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2. Logistic Regression CBOW\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to optimize\n",
    "params = [{\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag'],\n",
    "    'C': [0.3, 0.5, 0.7, 1],\n",
    "    'penalty': ['l2']\n",
    "    },{\n",
    "    'solver': ['liblinear','saga'],\n",
    "    'C': [0.3, 0.5, 0.7, 1],\n",
    "    'penalty': ['l1','l2']\n",
    "}]\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    n_jobs=-1 # Use all CPU\n",
    ")\n",
    "\n",
    "score_optimization(clf=clf,params=params,features='BOW',i=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Although the clustering results didn't have a train/test or cross-validation score, here we have a `Mutual_Info` score around twice the highest of our clusters. Above, `Mutual_Info` was very close to `Accuracy`, just two percentage points away. As we get more solutions we'll see the consistency between `Mutual_Info` and `Accuracy` among other classifiers. This will allow us to assess classification and clustering solutions by a fair mutual metric.\n",
    "\n",
    "### 5.4.3. Random Forest CBOW\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to compare\n",
    "params = {\n",
    "    'criterion':['entropy','gini'],\n",
    "}\n",
    "\n",
    "# Implement the classifier\n",
    "clf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features=None,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "score_optimization(clf=clf,params=params,features='BOW',i=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.4. Gradient Boosting CBOW\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to compare\n",
    "params = {\n",
    "    'learning_rate':[0.3,0.5,0.7,1]\n",
    "}\n",
    "\n",
    "# Implement the classifier\n",
    "clf = ensemble.GradientBoostingClassifier(\n",
    "    max_features=None\n",
    ")\n",
    "\n",
    "score_optimization(clf=clf,params=params,features='BOW',i=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "- Clearly classifiers obtain higher scores than clustering, this is despite being trained with less data.\n",
    "- So far `Accuracy` correlates perfectly with `Mutual_Info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "performance.iloc[:7].sort_values('Mutual_Info',ascending=False)[['Algorithm','n_train','Features','Mutual_Info','Test_Accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Unsupervised Feature Generation\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "\n",
    "## 6.1. Latent Semantic Analysis\n",
    "\n",
    "- Different from Bag-of-Words, Latent Semantic Analysis doesn't identify the most common words present in each article. Instead it identifies thematic components present in the text. Each cell doesn't contain a count, but rather a measure of how well a given feature is exemplified by the current document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.3, # drop words that occur in more than X percent of documents\n",
    "                             min_df=8, # only use words that appear at least X times\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "#Pass pandas series to our vectorizer model\n",
    "counts_tfidf = vectorizer.fit_transform(bow_counts.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that the content fed into the vectorizer is the same amount of data we used for BOW Counts. (500 articles in total, 50 by each author). We could use all of the 1000 articles, but first let's compare the LSA performance against BOW using the same data.\n",
    "- The vectorizer returns a CSR Matrix which can then be reduced as in PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reducing to 460 features will retain 98% of the explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(460)\n",
    "svd.fit(counts_tfidf)\n",
    "svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "lsa_data = lsa.fit_transform(counts_tfidf)\n",
    "lsa_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_data = pd.DataFrame(lsa_data)\n",
    "lsa_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Clustering on LSA (BOW Content)\n",
    "\n",
    "- We'll repeat the clustering and classification, now using the LSA features from the same 500 articles we used in BOW Counts.\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, establish X and Y\n",
    "y = bow_counts['author']\n",
    "X = lsa_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.24,\n",
    "                                                    random_state=0,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2. KMeans LSA\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust=KMeans()\n",
    "params={\n",
    "    'n_clusters': np.arange(10,30,5),\n",
    "    'init': ['k-means++','random'],\n",
    "    'n_init':[10,20],\n",
    "    'precompute_distances':[True,False]\n",
    "}\n",
    "evaluate_clust(clust,params,features='LSA',i=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3. Mean Shift LSA\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Declare and fit the model\n",
    "clust = MeanShift()\n",
    "\n",
    "params={\n",
    "    'bandwidth':[0.5,0.7,0.9]\n",
    "}\n",
    "evaluate_clust(clust,params,features='LSA',i=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4. Affinity Propagation LSA\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare and fit the model.\n",
    "clust = AffinityPropagation()\n",
    "\n",
    "params = {\n",
    "    'damping':[.5,.7,.9],\n",
    "    'max_iter':[200,500]\n",
    "}\n",
    "evaluate_clust(clust,params,features='LSA',i=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5. Spectral Clustering LSA\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "SpectralClustering can't be used with GridSearchCV because it lacks a .fit method. Therefore I won't use the function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust= SpectralClustering()\n",
    "\n",
    "params = {\n",
    "    'n_clusters':np.arange(10,26,5),\n",
    "    #'eigen_solver':['arpack','lobpcg',None],\n",
    "    'n_init':[15,25],\n",
    "    'assign_labels':['kmeans','discretize']\n",
    "}\n",
    "\n",
    "features='LSA'\n",
    "\n",
    "i=10\n",
    "\n",
    "t0=time()\n",
    "\n",
    "y_pred = clust.fit_predict(X)\n",
    "\n",
    "ari = adjusted_rand_score(y, y_pred)\n",
    "performance.loc[i,'ARI'] = ari \n",
    "print(\"Adjusted Rand-Index: %.3f\" % ari)\n",
    "\n",
    "hom = homogeneity_score(y,y_pred)\n",
    "performance.loc[i,'Homogeneity'] = hom\n",
    "print(\"Homogeneity Score: %.3f\" % hom)\n",
    "\n",
    "sil = silhouette_score(X,y_pred)\n",
    "performance.loc[i,'Silhouette'] = sil\n",
    "print(\"Silhouette Score: %.3f\" % sil)\n",
    "\n",
    "nmi = normalized_mutual_info_score(y,y_pred)\n",
    "performance.loc[i,'Mutual_Info'] = nmi\n",
    "print(\"Normed Mutual-Info Score: %.3f\" % nmi)\n",
    "\n",
    "performance.loc[i,'n_train'] = len(X)\n",
    "performance.loc[i,'Features'] = features\n",
    "performance.loc[i,'Algorithm'] = clust.__class__.__name__\n",
    "\n",
    "# Print contingency matrix\n",
    "crosstab = pd.crosstab(y, y_pred)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(crosstab, annot=True,fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()\n",
    "print(time()-t0,\"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results (See below)**\n",
    "\n",
    "- Based on `Mutual_Info` score, classification outperforms clustering regardless of the method used for feature-generation.\n",
    "- Within the clustering solutions however, LSA produced higher scores than BOW except for SpectralClustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.iloc[:11].sort_values('Mutual_Info',ascending=False)[['Algorithm','n_train','Features','Mutual_Info','Test_Accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Classification on LSA (BOW Content)\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "- Now we'll do supervised classification on the LSA features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1. Logistic Regression LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to optimize\n",
    "params = [{\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag'],\n",
    "    'C': [0.3, 0.5, 0.7, 1],\n",
    "    'penalty': ['l2']\n",
    "    },{\n",
    "    'solver': ['liblinear','saga'],\n",
    "    'C': [0.3, 0.5, 0.7, 1],\n",
    "    'penalty': ['l1','l2']\n",
    "}]\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    n_jobs=-1 # Use all CPU\n",
    ")\n",
    "\n",
    "score_optimization(clf=clf,params=params,features='LSA',i=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2. Random Forest LSA\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to compare\n",
    "params = {\n",
    "    'criterion':['entropy','gini'],\n",
    "}\n",
    "\n",
    "# Implement the classifier\n",
    "clf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features=None,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "score_optimization(clf=clf,params=params,features='LSA',i=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3. Gradient Boosting LSA\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to compare\n",
    "params = {\n",
    "    'learning_rate':[0.3,0.5,0.7,1]\n",
    "}\n",
    "\n",
    "# Implement the classifier\n",
    "clf = ensemble.GradientBoostingClassifier(\n",
    "    max_features=None\n",
    ")\n",
    "\n",
    "score_optimization(clf=clf,params=params,features='LSA',i=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "- Once again, classification trumps clustering regardless of the feature-generation method. \n",
    "- BOW features have performed consistently better than LSA on all classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.iloc[:14].sort_values('Mutual_Info',ascending=False)[['Algorithm','n_train','Features','Mutual_Info','Test_Accuracy']].iloc[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Clustering on LSA (All Content)\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "- Since LSA allows for very quick feature-generation, it's worth making a comparison between past results VS the utilization of all available data. After all, the LSA classifiers aren't far behind the BOW classifiers on 380 samples. With twice the number of articles LSA could very well outperform BOW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.3, # drop words that occur in more than X percent of documents\n",
    "                             min_df=8, # only use words that appear at least X times\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "#Pass pandas series to our vectorizer model\n",
    "counts_tfidf = vectorizer.fit_transform(authors_data.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that this time we fed all the articles into the vectorizer. See the size of the CSR Matrix underneath. The 1000 rows are 100 articles for each 10 authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This time we need 900 features to retain 98% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(900)\n",
    "svd.fit(counts_tfidf)\n",
    "svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "lsa_data = lsa.fit_transform(counts_tfidf)\n",
    "lsa_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lsa_data = pd.DataFrame(lsa_data)\n",
    "lsa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, establish X and Y\n",
    "y = authors_data['author']\n",
    "X = lsa_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.24,\n",
    "                                                    random_state=0,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The test data reflects the change in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1. KMeans LSA (All Content)\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust=KMeans()\n",
    "params={\n",
    "    'n_clusters': np.arange(10,30,5),\n",
    "    'init': ['k-means++','random'],\n",
    "    'n_init':[10,20],\n",
    "    'precompute_distances':[True,False]\n",
    "}\n",
    "evaluate_clust(clust,params,features='LSA',i=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2. Mean Shift LSA (All Content)\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Declare and fit the model\n",
    "clust = MeanShift()\n",
    "\n",
    "params={\n",
    "    'bandwidth':[0.5,0.7,0.9]\n",
    "}\n",
    "evaluate_clust(clust,params,features='LSA',i=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3. Affinity Propagation LSA (All Content)\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare and fit the model.\n",
    "clust = AffinityPropagation()\n",
    "\n",
    "params = {\n",
    "    'damping':[.5,.7,.9],\n",
    "    'max_iter':[200,500]\n",
    "}\n",
    "evaluate_clust(clust,params,features='LSA',i=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.4. Spectral Clustering LSA (All Content)\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "SpectralClustering can't be used with GridSearchCV because it lacks a .fit method. Therefore I won't use the function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust= SpectralClustering()\n",
    "\n",
    "params = {\n",
    "    'n_clusters':np.arange(10,26,5),\n",
    "    #'eigen_solver':['arpack','lobpcg',None],\n",
    "    'n_init':[15,25],\n",
    "    'assign_labels':['kmeans','discretize']\n",
    "}\n",
    "\n",
    "features='LSA'\n",
    "\n",
    "i=17\n",
    "\n",
    "t0=time()\n",
    "\n",
    "y_pred = clust.fit_predict(X)\n",
    "\n",
    "ari = adjusted_rand_score(y, y_pred)\n",
    "performance.loc[i,'ARI'] = ari \n",
    "print(\"Adjusted Rand-Index: %.3f\" % ari)\n",
    "\n",
    "hom = homogeneity_score(y,y_pred)\n",
    "performance.loc[i,'Homogeneity'] = hom\n",
    "print(\"Homogeneity Score: %.3f\" % hom)\n",
    "\n",
    "sil = silhouette_score(X,y_pred)\n",
    "performance.loc[i,'Silhouette'] = sil\n",
    "print(\"Silhouette Score: %.3f\" % sil)\n",
    "\n",
    "nmi = normalized_mutual_info_score(y,y_pred)\n",
    "performance.loc[i,'Mutual_Info'] = nmi\n",
    "print(\"Normed Mutual-Info Score: %.3f\" % nmi)\n",
    "\n",
    "performance.loc[i,'n_train'] = len(X)\n",
    "performance.loc[i,'Features'] = features\n",
    "performance.loc[i,'Algorithm'] = clust.__class__.__name__\n",
    "\n",
    "# Print contingency matrix\n",
    "crosstab = pd.crosstab(y, y_pred)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(crosstab, annot=True,fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()\n",
    "print(time()-t0,\"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. Classification on LSA (All Content)\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "- We've done clustering on LSA using all 1000 articles. Now let's classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1. Logistic Regression LSA (All Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to optimize\n",
    "params = [{\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag'],\n",
    "    'C': [0.3, 0.5, 0.7, 1],\n",
    "    'penalty': ['l2']\n",
    "    },{\n",
    "    'solver': ['liblinear','saga'],\n",
    "    'C': [0.3, 0.5, 0.7, 1],\n",
    "    'penalty': ['l1','l2']\n",
    "}]\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    n_jobs=-1 # Use all CPU\n",
    ")\n",
    "\n",
    "score_optimization(clf=clf,params=params,features='LSA',i=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2. Random Forest LSA\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to compare\n",
    "params = {\n",
    "    'criterion':['entropy','gini'],\n",
    "}\n",
    "\n",
    "# Implement the classifier\n",
    "clf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features=None,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "score_optimization(clf=clf,params=params,features='LSA',i=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3. Gradient Boosting LSA\n",
    "\n",
    "[Back to Outline](#Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to compare\n",
    "params = {\n",
    "    'learning_rate':[0.3,0.5,0.7,1]\n",
    "}\n",
    "\n",
    "# Implement the classifier\n",
    "clf = ensemble.GradientBoostingClassifier(\n",
    "    max_features=None\n",
    ")\n",
    "\n",
    "score_optimization(clf=clf,params=params,features='LSA',i=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Results:**\n",
    "\n",
    "The results of more data are mixed with other methods. The LogisticRegression LSA with 760 samples is above GradientBoosting with 380, but below LogisticRegression with 380.\n",
    "- **n_train**. Overal the 380 train size which is the 75% train split from the 500 BOW set generated higher scores than larger sizes.\n",
    "- **Features**. Overall BOW features produced higher scores than most LSA features.\n",
    "- **Supervised VS Unsupervised**. Classification produced indisputably  higher scores than clustering regardless of size or feature-generation ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.sort_values('Mutual_Info',ascending=False)[['Algorithm','n_train','Features','Mutual_Info','Test_Accuracy']].iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Choosing Model\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "## 7.1. Comparing Scores\n",
    "\n",
    "- Since we tracked several scores throughout our testing, let's first compare our scores. The table below is sorted by `Mutual_Info` score.\n",
    "-  The first three scores `Mutual_Info, ARI, Homogeneity` are most commonly used for clustering. `Cross_Val, Train_Accuracy, Test_Accuracy` are limited to classification. Therefore the `NaN` missing values are the clustering algorithms.\n",
    "- Notice that `Mutal_Info` scores and `Test_Accuracy` are very closely related to one another. \n",
    "    - `Homogeneity` is close as well, but it gives 0.99 for index 15, which is a clustering algorithm with several dozens of clusters. Homogeneity will reward clustering solutions with numerous `n_clusters` because it penalizes clusters containing mixed true_labels. But so many clusters are practically useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.sort_values('Mutual_Info',ascending=False)[['Mutual_Info','ARI','Homogeneity','Cross_Val','Train_Accuracy','Test_Accuracy']].iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Sorting by Test_Accuracy\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "Although we established that `Mutual_Info` and `Test_Accuracy` are very closely aligned, if we sort by `Test_Accuracy` there is a slight difference in top performers.\n",
    "- First of all, since clustering solutions have missing values they are all at the bottom.\n",
    "- All the BOW solutions are still at the top.\n",
    "- LogisticRegression 760 LSA is now above itself at 380 samples. For RandomForest however, less samples produced a higher test accuracy. Same goes for GradientBoosting underneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.sort_values('Test_Accuracy',ascending=False)[['Algorithm','n_train','Features','Mutual_Info','Test_Accuracy']].iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Winner\n",
    "\n",
    "[Back to Outline](#Outline)\n",
    "\n",
    "**Algorithm** \n",
    "\n",
    "Clearly LogisticRegression has done a better job at predicting the author name regardless of other factors. Across varying train size and feature-generation, 3 out of the 5 top solutions are from LogisticRegression.\n",
    "\n",
    "**Feature-Generation**\n",
    "\n",
    "For the purposes of predicting author's names, classification on BOW features has outperformed LSA. However LSA could be more appropriate for other tasks. Perhaps an author's uniqueness is more palbable from his vocabulary than from the semantics of his writing. This may explain why BOW was superior in this project.\n",
    "\n",
    "**Train_Size**\n",
    "\n",
    "Train size produced dubious variations in LSA. More data helped LogisticRegression but made others less accurate. It would be nice to see the effects of Train size in BOW, but that takes a long time.\n",
    "\n",
    "**Score**\n",
    "\n",
    "Normalized Mutual Information is definitely the best score with which to compare clustering and classification algorithms. Other scores also also have a close resemblance, therefore I'd recommend to always compare several clustering scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = performance.sort_values('Test_Accuracy',ascending=False)[['Algorithm','Features','n_train','Test_Accuracy']].iloc[:9]\n",
    "\n",
    "plot_data.n_train = plot_data.n_train.apply(lambda x: str(x))\n",
    "plot_data['method'] = plot_data.Features+'_'+plot_data.n_train\n",
    "%matplotlib inline\n",
    "\n",
    "sns.catplot(col='Algorithm',x='method',y='Test_Accuracy',\n",
    "            data=plot_data,kind='bar')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
