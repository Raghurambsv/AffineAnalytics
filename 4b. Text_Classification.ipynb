{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content</h3>\n",
    "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Library-and-Data\" role=\"tab\" aria-controls=\"profile\">Library and Data<span class=\"badge badge-primary badge-pill\"></span></a>\n",
    "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Reading-Data\" role=\"tab\" aria-controls=\"messages\">Reading Data<span class=\"badge badge-primary badge-pill\"></span></a>\n",
    "  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#Logistic-Regression-Classifier\" role=\"tab\" aria-controls=\"settings\">Logistic Regression Classifier<span class=\"badge badge-primary badge-pill\"></span></a>\n",
    "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Support-Vector-Classifier\" role=\"tab\" aria-controls=\"settings\">Support Vector Classifier<span class=\"badge badge-primary badge-pill\"></span></a> \n",
    "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Multinomial-Naive-Bayes-Classifier\" role=\"tab\" aria-controls=\"settings\">Multinomial Naive Bayes Classifier<span class=\"badge badge-primary badge-pill\"></span></a>\n",
    "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Bernoulli-Naive-Bayes-Classifier\" role=\"tab\" aria-controls=\"settings\">Bernoulli Naive Bayes Classifier<span class=\"badge badge-primary badge-pill\"></span></a>\n",
    "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Gradient-Boost-Classifier\" role=\"tab\" aria-controls=\"settings\">Gradient Boost Classifier<span class=\"badge badge-primary badge-pill\"></span></a>\n",
    "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#XGBoost-Classifier\" role=\"tab\" aria-controls=\"settings\">XGBoost Classifier<span class=\"badge badge-primary badge-pill\"></span></a>  \n",
    "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Random-Forest-Classifier\" role=\"tab\" aria-controls=\"settings\">Random Forest Classifier<span class=\"badge badge-primary badge-pill\"></span></a>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "\n",
    "import nltk\n",
    "import nltk as nlp\n",
    "import string\n",
    "import re\n",
    "true = pd.read_csv(\"dataset/True.csv\")\n",
    "fake = pd.read_csv(\"dataset/Fake.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Text-Classification\" role=\"tab\" aria-controls=\"profile\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date target  \n",
       "0  December 31, 2017   fake  \n",
       "1  December 31, 2017   fake  \n",
       "2  December 30, 2017   fake  \n",
       "3  December 29, 2017   fake  \n",
       "4  December 25, 2017   fake  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake['target'] = 'fake'\n",
    "true['target'] = 'true'\n",
    "news = pd.concat([fake, true]).reset_index(drop = True)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Text-Classification\" role=\"tab\" aria-controls=\"profile\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this algorithm, the probabilities describing the possible outcomes of a single trial are modelled using a logistic function.\n",
    "It is used to model the probability of a certain class or event existing \n",
    "such as pass/fail, win/lose, alive/dead or healthy/sick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.76%\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(news['text'], news.target, test_size=0.2, random_state=2020)\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', LogisticRegression())])\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4674   66]\n",
      " [  45 4195]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.99      0.99      0.99      4740\n",
      "        true       0.98      0.99      0.99      4240\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Text-Classification\" role=\"tab\" aria-controls=\"profile\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support vector machine is a classifier that represents the training data as points in space separated into categories by a gap as wide as possible. \n",
    "New points are then added to space by predicting which category they fall into and which space they will belong to.\n",
    "\n",
    "More often text classification use cases will have linearly separable data and LinearSVC is apt for such scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.55%\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(news['text'], news.target, test_size=0.2, random_state=2020)\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', LinearSVC())])\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4720   20]\n",
      " [  20 4220]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      1.00      1.00      4740\n",
      "        true       1.00      1.00      1.00      4240\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Text-Classification\" role=\"tab\" aria-controls=\"profile\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is based on Bayes’s theorem which gives an assumption of independence among predictors. \n",
    "A Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. \n",
    "MultinomialNB implements the naive Bayes algorithm for multinomially distributed data,it works with occurrence counts of words and to form vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.56%\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', MultinomialNB())])\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4486  254]\n",
      " [ 324 3916]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.95      0.94      4740\n",
      "        true       0.94      0.92      0.93      4240\n",
      "\n",
      "    accuracy                           0.94      8980\n",
      "   macro avg       0.94      0.93      0.94      8980\n",
      "weighted avg       0.94      0.94      0.94      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Text-Classification\" role=\"tab\" aria-controls=\"profile\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes Classifier\n",
    "BernoulliNB implements the naive Bayes training and classification algorithms for data that is distributed according to multivariate Bernoulli distributions; i.e., there may be multiple features but each one is assumed to be a binary-valued (Bernoulli, boolean) variable. Therefore, this class requires samples to be represented as binary-valued feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 94.14%\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', BernoulliNB())])\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4377  363]\n",
      " [ 163 4077]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.96      0.92      0.94      4740\n",
      "        true       0.92      0.96      0.94      4240\n",
      "\n",
      "    accuracy                           0.94      8980\n",
      "   macro avg       0.94      0.94      0.94      8980\n",
      "weighted avg       0.94      0.94      0.94      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Text-Classification\" role=\"tab\" aria-controls=\"profile\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB builds an additive model in a forward stage-wise fashion\n",
    "It allows for the optimization of arbitrary differentiable loss functions. \n",
    "Binary classification is a special case where only a single regression tree is induced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.52%\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', GradientBoostingClassifier(loss = 'deviance',\n",
    "                                                   learning_rate = 0.01,\n",
    "                                                   n_estimators = 10,\n",
    "                                                   max_depth = 5,\n",
    "                                                   random_state=55))])\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4707   33]\n",
      " [  10 4230]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.99      1.00      4740\n",
      "        true       0.99      1.00      0.99      4240\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Text-Classification\" role=\"tab\" aria-controls=\"profile\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. \n",
    "Rather than training all the models in isolation of one another, boosting trains models in succession\n",
    "with each new model being trained to correct the errors made by the previous ones\n",
    "\n",
    "In a standard ensemble method where models are trained in isolation, all of the models might simply end up making the same mistakes.\n",
    "We should use this algorithm when we require fast and accurate predictions after the model is deployed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:50:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 99.52%\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', XGBClassifier(loss = 'deviance',\n",
    "                                                   learning_rate = 0.01,\n",
    "                                                   n_estimators = 10,\n",
    "                                                   max_depth = 5,\n",
    "                                                   random_state=2020))])\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4707   33]\n",
      " [  10 4230]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.99      1.00      4740\n",
      "        true       0.99      1.00      0.99      4240\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Text-Classification\" role=\"tab\" aria-controls=\"profile\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest are an ensemble learning method.\n",
    "It operates by constructing a multitude of decision trees at training time and outputs the class that is the mode of the classes of the individual trees.\n",
    "A random forest is a meta-estimator that fits a number of trees on various subsamples of data sets and then uses an average to improve the accuracy in the model’s predictive nature.\n",
    "The sub-sample size is always the same as that of the original input size but the samples are often drawn with replacements.\n",
    "\n",
    "We should use this algorithm when we need high accuracy while working with large datasets with higher dimensions. We can also use it if there are missing values in the dataset. We should not use it if we have less time for modeling or if large computational costs and memory space are a constrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.18%\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', RandomForestClassifier())])\n",
    "\n",
    "model = pipe.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4705   35]\n",
      " [  39 4201]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.99      0.99      0.99      4740\n",
      "        true       0.99      0.99      0.99      4240\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Text-Classification\" role=\"tab\" aria-controls=\"profile\">Go to top<span class=\"badge badge-primary badge-pill\"></span></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
